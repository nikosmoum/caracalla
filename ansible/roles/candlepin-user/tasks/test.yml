---
- name: pause for tomcat before restart
  pause:
    minutes: 3

- name: Restart tomcat
  service:
    name: tomcat
    state: restarted
  become: true

- name: pause for tomcat to start
  pause:
    minutes: 3

- name: Verify candlepin has started
  get_url:
    url: https://localhost:8443/candlepin/status
    dest: /tmp/status_result.txt
    validate_certs: no
    timeout: 360

- name: Write test properties to properties file
  lineinfile:
    line: "{{item}}"
    dest: "{{candlepin_user_home}}/candlepin-throughput/candlepin-throughput.prop"
  with_items: "{{candlepin_throughput_properties}}"

- name: Remove results file if present
  file:
    path: "{{caracalla_checkout}}/{{item.value.result_file}}"
    state: absent
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Remove parsed results file if present
  file:
    path: "{{caracalla_checkout}}/parsed-{{item.value.result_file}}"
    state: absent
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Run jmeter test
  command: "/opt/apache-jmeter-3.0/bin/jmeter -n -t {{caracalla_checkout}}/{{item.value.folder}}/{{item.value.test_name}} -p {{item.value.property_file}}"
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step
    - skip_ansible_lint

- name: Parse result
  command: "./parse-jtl.py --no-colors --pretty-print {{item.value.result_file}} -o parsed-{{item.value.result_file}} --generate-histograms {{item.value.result_file}}.graphs.pdf"
  args:
    chdir: "{{caracalla_checkout}}"
    creates: "{{caracalla_checkout}}/parsed-{{item.value.result_file}}"
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Delete existing artifacts folder from workspace
  local_action: file  dest="artifacts/" state=absent

- name: Create artifacts folder
  local_action: file  dest="artifacts/" state=directory

- name: Fetch results files
  fetch:
    src: "{{caracalla_checkout}}/{{item.value.result_file}}"
    dest: "artifacts/{{item.value.result_file}}"
    flat: yes
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Fetch parsed results files
  fetch:
    src: "{{caracalla_checkout}}/parsed-{{item.value.result_file}}"
    dest: "artifacts/parsed-{{item.value.result_file}}"
    flat: yes
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Fetch parsed results graphs
  fetch:
    src: "{{caracalla_checkout}}/{{item.value.result_file}}.graphs.pdf"
    dest: "artifacts/{{item.value.result_file}}.graphs.pdf"
    flat: yes
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  tags:
    - jmeter-step

- name: Fetch candlepin.log
  fetch:
    src: "/var/log/candlepin/candlepin.log"
    dest: "artifacts/candlepin.log"
    flat: yes
    validate_checksum: no
  when: keep_logs

- name: Fetch access.log
  fetch:
    src: "/var/log/candlepin/access.log"
    dest: "artifacts/access.log"
    flat: yes
    validate_checksum: no
  when: keep_logs

- name: Compare results
  command: "./parse-jtl.py -c {{item.value.result_file}} -b {{item.value.folder}}/{{item.value.baseline}} -e {{item.value.folder}}/{{item.value.expected}} -n -o {{item.value.folder}}/{{item.value.comparision_result}}"
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step

- name: Fetch compare.txt
  fetch:
    src: "{{item.value.folder}}/{{item.value.comparision_result}}"
    dest: "artifacts/{{item.value.folder}}-{{item.value.comparision_result}}"
    flat: yes
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"

- name: Initialize variables
  set_fact:
    passed_tests: []
    failed_tests: []

- name: Grep passed tests
  shell: 'grep "\[OK\]" {{item.value.folder}}/{{item.value.comparision_result}} || true'
  register: passed_tests_dict
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step

- name: Set variable with passed tests
  set_fact: passed_tests="{{passed_tests}} + {{item.stdout_lines}}"
  when: item.changed == true
  with_items: "{{passed_tests_dict.results}}"

- name: Grep failed tests from results
  shell: 'grep "\[FAILED\]" {{item.value.folder}}/{{item.value.comparision_result}} || true'
  register: failed_tests_dict
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step

- name: Set variable with failed tests
  set_fact: failed_tests="{{failed_tests}} + {{item.stdout_lines}}"
  when: item.changed == true
  with_items: "{{failed_tests_dict.results}}"

- name: Show passed tests
  debug:
    msg: "{{passed_tests}}"
  when: passed_tests != []

- name: Show failed tests
  debug:
    msg: "{{failed_tests}}"
  when: failed_tests != []

- name: Check for failed tests
  shell: '! grep "\[FAILED\]" {{item.value.folder}}/{{item.value.comparision_result}} > /dev/null'
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step

- set_fact:
    current_date: "{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}-{{ ansible_date_time.minute }}"

- set_fact:
    major_minor: "{{baseline_branch | major_minor()}}"

- name: Debug baseline_branch and major_minor
  debug:
    msg: "{{baseline_branch}} {{major_minor}}"

- name: Save successful result in JSON format to shared NFS directory
  shell: './parse-jtl.py  -p {{item.value.result_file}} -o {{perf_results_dir}}/{{item.key}}/{{major_minor}}/{{current_date}}.json'
  with_dict: "{{jmeter_test_details}}"
  when: "item.key in jmeter_tests"
  args:
    chdir: "{{caracalla_checkout}}"
  tags:
    - jmeter-step
